# ðŸŽ‰ graphrag v1.0.0 â€” First public release

Date: 2025-09-26

Welcome to the very first official release of graphrag! This release marks a milestone â€” the core Retrieval-Augmented Generation (RAG) pipeline is ready for use. Thank you to everyone who helped test, file issues, and contribute ideas. Let's jump into what's included.

## Highlights

- Core RAG pipeline: ingest documents, chunk them, compute embeddings, store them in the graph database (Neo4j), retrieve relevant chunks, and generate grounded answers using OpenAI or Ollama LLM backends.
- Multi-format ingestion: the `loaders/` and `ingestion/` modules support PDFs, DOCX, PPTX, CSV and plain text files, with a pluggable loader system.
- Graph-backed retrieval: document chunks are stored in a Neo4j graph to enable relationship-aware retrieval and visualization of document relationships (see `core/graph_db.py` and `core/graph_viz.py`).
- LLM integration: a unified `LLMManager` (`core/llm.py`) supports OpenAI and Ollama providers with clean fallbacks and response post-processing to remove HTML/LaTeX artifacts.
- Chainlit and web UI wiring (starter): interactive UI wiring is included to let you upload documents and ask questions in real time.
- Dev-friendly scripts: `scripts/ingest_documents.py`, `scripts/create_similarities.py`, and `scripts/setup_neo4j.py` help bootstrap datasets and indexes quickly.

## Fixed reported issues

- Improved HTML and LaTeX cleanup in generated answers (see `core/llm.py`) to ensure plain-text responses without broken markup.
- Cleaner chunking heuristics and improved default chunk size/tokens in `core/chunking.py`.
- Better error handling when LLM calls fail, with logged errors and clearer exceptions.
- Docker/CI: initial workflow to build and publish images to GHCR was added and documented.

## Files of interest

- `core/llm.py` â€” LLMManager with generate_rag_response and cleaning helper
- `core/chunking.py` â€” chunking utilities and heuristics
- `core/graph_db.py` & `core/graph_viz.py` â€” Neo4j integration and visualization helpers
- `ingestion/document_processor.py` & `loaders/*` â€” document ingestion pipeline
- `scripts/` â€” helper scripts for ingestion, similarity creation and Neo4j setup

## Upgrade notes / breaking changes

- This is the first release; there are no prior versions to migrate from. Default settings are in `config/settings.py` â€” double-check OpenAI/Ollama API settings and Neo4j connection info before ingesting large datasets.

## Thank you

This project exists because of many helpful testers and idea contributors. If you find issues, please open them on GitHub â€” your feedback helps shape the roadmap.

Happy building,

The graphrag contributors
